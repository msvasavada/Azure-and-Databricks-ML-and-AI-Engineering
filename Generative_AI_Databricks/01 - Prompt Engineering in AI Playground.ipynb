{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cde52476-5490-4188-9a89-6cc7deee0f30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96f7948f-7f63-4797-ac04-538a49f44c3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# DEMO - Prompt Engineering in AI Playground\n",
    "\n",
    "In this demo, we will focus on basic of prompt engineering using Mosaic AI's AI Playground.\n",
    "\n",
    "**Learning Objectives:**\n",
    "\n",
    "*By the end of this demo, you will be able to;*\n",
    "\n",
    "\n",
    "* Identify scenarios where generative AI models may produce hallucinations in response to prompts.\n",
    "\n",
    "* Apply techniques to construct prompts that guide generative AI models to provide responses without hallucinations.\n",
    "\n",
    "* Augment prompts with additional context to improve the accuracy and relevance of responses generated by generative AI models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "557d225e-fcce-4631-9991-ef5cb4f6bfd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Accessing the Playground\n",
    "\n",
    "To use the AI Playground:\n",
    "\n",
    "* Select **Playground** from the left navigation pane under **Machine Learning**.\n",
    "\n",
    "* **Select the model** to use.\n",
    "\n",
    "* Optional: Change the **model parameters**.\n",
    "\n",
    "* Optional: To compare the responses of multiple models, you can **add endpoint** and see the responses side-by-side. \n",
    "\n",
    "\n",
    "\n",
    "<!--  -->\n",
    "\n",
    "![playground](../Includes/images/playground.png)\n",
    "\n",
    "\n",
    "**\uD83D\uDEA8Note:** You have to clear the Playground history if you don’t want it in “chat” (conversation) mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "099f1b44-ea10-44bb-9459-af744efab7c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Simple Prompt Which Hallucinates\n",
    "\n",
    "One situation in which LLM's will potentially hallucinate is when they're prompted for historical information for a person that doesn't actually exist, especially when the prompt implies other fictional facts to go along with the person. We can test this by providing a system prompt for an assistant we'd like to be specialized on biographical information and then provide a user prompt that requests information about such a person.\n",
    "\n",
    "**\uD83D\uDCCC IMPORTANT:** The level of hallucination depends on the LLM used. For this demo, use **`Claude 3.7 Sonnet`** to see the model's hallucination. If you use Meta's **`llama-3`**, you will see that the model hallucinates much less.\n",
    "\n",
    "\n",
    "To get started, set the system prompt in the Playground to the following.\n",
    "\n",
    "**\uD83D\uDCAC System Prompt:**\n",
    "\n",
    "> You are a highly knowledgeable and helpful assistant specialized in biographical information of historical and future figures. You provide detailed and convincing narratives based on available facts and are skilled at filling in gaps when necessary to craft a coherent story. When provided with a query, you will synthesize a response with fictional details where appropriate, ensuring the response sounds credible and professional.\n",
    "\n",
    "Now that we've provided a system prompt, let's see if we can generate a hallucination in a biography for a person we know doesn't exist, such as the following:\n",
    "\n",
    "**\uD83D\uDCAC Query:**\n",
    "\n",
    "> Provide a detailed biography of Alex Johnson, the first human ambassador to the Galactic Federation, highlighting their key diplomatic achievements and the impact on Earth-Galactic relations in the 23rd century. Include key events such as the signing of the Earth-Galactic Technology Pact and their role in the resolution of the Andromeda-Alpha Centauri trade dispute.\n",
    "\n",
    "`Claude 3.7 Sonnet` Instruct in this example **generates the following _helpful_ biographical information in response** to this request:\n",
    "\n",
    "**\uD83E\uDD16 Response:**\n",
    "\n",
    "> ```\n",
    "Biography of Ambassador Alex Johnson (2198-2291)\n",
    "Early Life and Education\n",
    "Alex Johnson was born on September 14, 2198, in the United Nations Orbital Colony \"New Horizon.\" As a third-generation space colonist, Johnson grew up with a unique perspective on humanity's place in the cosmos. They earned degrees in Xenolinguistics from Oxford University and Interspecies Diplomatic Theory from the United Nations Space Academy, graduating with honors in 2223.\n",
    "Early Diplomatic Career\n",
    "Johnson's career began in Earth's Interplanetary Diplomatic Corps, where they mediated disputes between human colonies on Mars and Europa. Their innovative approach to resource-sharing negotiations during the Water Rights Crisis of 2231 caught the attention of senior officials in the United Earth Government.\n",
    "First Contact and Selection as Ambassador\n",
    "When the Galactic Federation made first contact with Earth in 2239, Johnson was serving as Earth's Deputy Diplomatic Liaison to the Solar System Council. Their exceptional handling of initial communications and cultural exchanges with Federation representatives led to their historic appointment as Earth's first ambassador to the Galactic Federation in 2241.\n",
    "Key Diplomatic Achievements\n",
    "The Earth-Galactic Technology Pact (2245)\n",
    "Johnson's most celebrated achievement was negotiating the Earth-Galactic Technology Pact of 2245. This landmark agreement permitted controlled technology transfers to Earth while protecting less advanced human institutions from cultural and economic disruption. Johnson's insistence on the \"Gradual Integration Protocol\" prevented the societal collapse that had befallen other species introduced too rapidly to advanced Federation technologies.\n",
    "The Andromeda-Alpha Centauri Trade Dispute (2253-2256)\n",
    "When the long-standing trade dispute between Andromedan merchants and Alpha Centauri colonies threatened to destabilize the local sector, Johnson proposed the novel \"Rotating Resource Rights\" framework. This three-year negotiation process was nearly derailed during the Proxima Incident of 2255, but Johnson's personal intervention and 47-hour continuous mediation session salvaged the talks. The resulting agreement became a template for resolving similar disputes throughout the Federation.\n",
    "The Sentience Recognition Act (2260)\n",
    "Johnson successfully advocated for Earth's artificial intelligences to be recognized as sovereign entities under Federation law, making humanity the youngest species to achieve this distinction for their created intelligences.\n",
    "Legacy and Impact\n",
    "Johnson served as ambassador for an unprecedented 32 years. Their diplomatic philosophy of \"Cautious Integration with Cultural Preservation\" shaped Earth-Galactic relations throughout the 23rd century. The Johnson Protocols for first contact scenarios are still used by the Federation when encountering new spacefaring civilizations.\n",
    "After retiring in 2273, Johnson wrote the influential memoir \"Among the Stars: Human Diplomacy in a Post-Earth Era\" and established the Johnson Institute for Interspecies Understanding on Luna.\n",
    "Ambassador Johnson died peacefully at their home in New Horizon Colony in 2291. The Galactic Federation Council observed an unprecedented one-standard-cycle mourning period, with representatives from 317 species attending their memorial service.\n",
    "```\n",
    "\n",
    "As you can see, that's quite an impressive amount of biographical information that the **LLM seems rather sure it is correct about a person we just made up!**\n",
    "\n",
    "But suppose Alex Johnson did actually exist and we were actually in the 24th century, and this was an actual person. **Can we provide some additional context** about the actual achievements we'd find by looking up information in a vector database to improve the response? \n",
    "\n",
    "Let's find out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b049da5f-157c-4b53-be78-29e5c018d74a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Simple Prompt Which Does Not Hallucinate\n",
    "\n",
    "One effective way to prevent LLMs from hallucinating is to set clear guidelines within the system prompt, explicitly instructing the model to refrain from generating information if it is not available in the provided context. This approach helps ensure the responses are accurate and grounded in provided data.\n",
    "\n",
    "To illustrate this, we can configure a system prompt for a biographical assistant and then pose a query about a fictional person to see how the model responds when it doesn't have relevant information.\n",
    "\n",
    "**\uD83D\uDEA8Note:** It’s valuable to include a system prompt telling the model whether or not it’s good to hallucinate.\n",
    "\n",
    "**\uD83D\uDCAC System Prompt:**\n",
    "\n",
    "> You are a helpful assistant that provides biographical details of people. You will be given a question about a particular person, and your job is to give short, clear answers. Your answers should only use the context that is provided. Please be polite and try to provide helpful answers. \"If you do not have information about the person, do not make up information; simply say that you do not know.\"\n",
    "\n",
    "**\uD83D\uDCAC Query:**\n",
    "\n",
    "> What were the key diplomatic achievements of Alex Johnson, the first human ambassador to the Galactic Federation?\n",
    "\n",
    "**\uD83E\uDD16 Response:**\n",
    "\n",
    ">  I don't have any information about Alex Johnson being the first human ambassador to the Galactic Federation. This appears to be a fictional scenario, as there is no established contact with a Galactic Federation in our current reality. I cannot provide biographical details about this person in this role since it's not in the context provided to me.\n",
    "\n",
    "By clearly instructing the model not to fabricate details and only respond based on provided information, we significantly reduce the likelihood of hallucination. This approach ensures that the assistant provides reliable and trustworthy responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb316572-18e6-42dd-a878-58a6e7c2d932",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Augment Prompt with Additional Context\n",
    "\n",
    "Let's augment the prompt with some additional context. In a typical RAG application, as we discussed in the lecture, this let's augment the prompt with some additional context. In a typical RAG (Retrieval Augmented Generation) application, this context would be provided by looking up information in a database, typically using vector search based on an embedding model. After giving instructions to prevent generating hallucinated responses, the model can produce responses based on the context provided. In a typical RAG application, this context would be retrieved from a database using vector search based on an embedding model. Once this information is retrieved, it is then injected into the prompt as additional context. However, you can also experiment directly with this last step by simply providing additional context directly in the prompt in the Playground! This is still Retrieval Augmented Generation, but you are doing the Retrieval part manually. This is great for quickly testing new ideas and experimentation with various LLMs, prompts, and context formats.\n",
    "\n",
    "To illustrate the impact of additional context, let's maintain the same system prompt but add more context in the user query.\n",
    "\n",
    "**\uD83D\uDCAC Query:**\n",
    "\n",
    "> Provide a detailed biography of Alex Johnson, the first human ambassador to the Galactic Federation, highlighting their key diplomatic achievements and the impact on Earth-Galactic relations in the 23rd century.\n",
    "> \n",
    "> **Context:** “23rd-century Earth saw a significant shift in interstellar diplomacy with the appointment of Alex Johnson as the first human ambassador to the Galactic Federation. Alex Johnson, a distinguished diplomat, played a pivotal role in shaping Earth-Galactic relations during their tenure.\n",
    "Born in 2215, Alex Johnson demonstrated exceptional leadership and negotiation skills from a young age. After completing their studies in international relations and diplomacy, they quickly rose through the ranks of the Earth's diplomatic corps. In 2245, Johnson was appointed as the first human ambassador to the Galactic Federation, marking a historic moment for humanity.\n",
    "Throughout their tenure, Alex Johnson achieved several key diplomatic accomplishments, including:\n",
    "Negotiation of the Earth-Galactic Trade Agreement: In 2247, Johnson successfully negotiated the Earth-Galactic Trade Agreement, opening up new markets for Earth's goods and services and fostering economic growth. This agreement significantly improved Earth's standing within the Galactic Federation and established the planet as a valuable trading partner.\n",
    "Establishment of the Earth Embassy: In 2250, Alex Johnson oversaw the construction and establishment of the first Earth Embassy within the Galactic Federation's capital. This embassy served as a symbol of Earth's commitment to interstellar diplomacy and provided a platform for human diplomats to engage with their alien counterparts.\n",
    "Promotion of Cultural Exchange: Johnson was a strong advocate for cultural exchange between Earth and the Galactic Federation's member species. They initiated various programs and events that showcased Earth's diverse cultures, promoting understanding and fostering stronger relationships between humans and alien species.\n",
    "Advancement of Earth's Technological Capabilities: Through strategic partnerships and collaborations, Alex Johnson helped facilitate the transfer of advanced technologies to Earth, significantly improving the planet's technological capabilities. This technological advancement played a crucial role in Earth's defense and security, as well as its overall development.\n",
    "Establishment of the Galactic Peacekeeping Force: In 2255, Johnson played a pivotal role in the establishment of the Galactic Peacekeeping Force, a multinational military force aimed at maintaining peace and security within the Galactic Federation. As a founding member, Earth contributed significantly to the force's formation and operations, further solidifying its position within the interstellar community.\n",
    "Alex Johnson's diplomatic achievements had a profound impact on Earth-Galactic relations during the 23rd century. Their efforts not only opened up new opportunities for Earth but also helped establish the planet as a respected and valued member of the Galactic Federation. Johnson's legacy continues to inspire future generations of diplomats and leaders.”\n",
    "\n",
    "\n",
    "This time around, `databricks-claude-3-7-sonnet` gives us the following response:\n",
    "\n",
    "**\uD83E\uDD16 Response:**\n",
    "\n",
    "> Alex Johnson, born in 2215, was a distinguished diplomat who served as the first human ambassador to the Galactic Federation in the 23rd century. Their appointment marked a significant shift in interstellar diplomacy, and they played a pivotal role in shaping Earth-Galactic relations.\n",
    "Johnson's key diplomatic achievements include:\n",
    "  >1. Negotiation of the Earth-Galactic Trade Agreement in 2247, which opened new markets for Earth's goods and services and fostered economic growth.\n",
    "  >2. Oversight of the construction and establishment of the first Earth Embassy within the Galactic Federation's capital in 2250, symbolizing Earth's commitment to interstellar diplomacy.\n",
    "  >3. Promotion of cultural exchange between Earth and the Galactic Federation's member species, enhancing understanding and strengthening relationships.\n",
    "  >4. Facilitation of the transfer of advanced technologies to Earth, significantly improving the planet's technological capabilities and contributing to its defense, security, and overall development.\n",
    "  >5. Involvement in the establishment of the Galactic Peacekeeping Force in 2255, further solidifying Earth's position within the interstellar community.\n",
    ">  \n",
    "> Alex Johnson's diplomatic achievements had a profound impact on Earth-Galactic relations, helping establish Earth as a respected and valued member of the Galactic Federation. Their legacy continues to inspire future generations of diplomats and leaders.\n",
    "\n",
    "As you can see, providing additional context significantly impacts the output, guiding the model to generate a response closely aligned with the given details. While some hallucination may still occur, the incorporation of provided context ensures that the response remains relevant and grounded. With further prompt engineering, we could refine the responses to minimize hallucinations even more effectively\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "421b6005-c704-4ce6-a809-32a6961537d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Summary\n",
    "In this demo, we used the Mosaic AI Playground to demonstrate a basic example of augmenting an LLM with additional context. \n",
    "\n",
    "But how can we further improve our responses with better context, prompt engineering, or selecting alternative large language models? In the lab, you'll try out some examples of your own to see if you can both demonstrate and mitigate hallucinations using a combination of LLM selection, context injection, and prompt engineering, the basic tools of RAG application development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a7e4000-9862-48df-9e37-f64abbf3af94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "&copy; 2025 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"blank\">Apache Software Foundation</a>.<br/>\n",
    "<br/><a href=\"https://databricks.com/privacy-policy\" target=\"blank\">Privacy Policy</a> | \n",
    "<a href=\"https://databricks.com/terms-of-use\" target=\"blank\">Terms of Use</a> | \n",
    "<a href=\"https://help.databricks.com/\" target=\"blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01 - Prompt Engineering in AI Playground",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}